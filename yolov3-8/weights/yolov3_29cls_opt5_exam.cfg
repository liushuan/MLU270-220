[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=16
subdivisions=1
width=512
height=512
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 500200
policy=steps
steps=400000,450000
scales=.1,.1

[convolutional]
batch_normalize=1
filters=24
size=3
stride=1
pad=1
activation=leaky

# Downsample 1

[convolutional]
batch_normalize=1
filters=48
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=48
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample 2   5

[convolutional]
batch_normalize=1
filters=96
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=96
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=96
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample 3   12

[convolutional]
batch_normalize=1
filters=160
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=96
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=160
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=96
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=160
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=96
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=160
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=96
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=160
size=3
stride=1
pad=1
activation=leaky
####################### layer:24

[shortcut]
from=-3
activation=linear

# Downsample 4

[convolutional]
batch_normalize=1
filters=240
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=160
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=240
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=160
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=240
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=160
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=240
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=160
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=240
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=160
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=240
size=3
stride=1
pad=1
activation=leaky
####################### layer:40

[shortcut]
from=-3
activation=linear

# Downsample 5

[convolutional]
batch_normalize=1
filters=360
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=240
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=360
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=240
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=360
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=240
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=360
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=240
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=360
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

######################  54

[convolutional]
batch_normalize=1
filters=240
size=1
stride=1
pad=1
activation=leaky


[convolutional]
batch_normalize=1
filters=360
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=240
size=1
stride=1
pad=1
activation=leaky

### SPP ###
[maxpool]
stride=1
size=5

[route]
layers=-2

[maxpool]
stride=1
size=9

[route]
layers=-4

[maxpool]
stride=1
size=13

[route]
layers=-1,-3,-5,-6
### End SPP ###

[convolutional]
batch_normalize=1
filters=240
size=1
stride=1
pad=1
activation=leaky


[convolutional]
batch_normalize=1
filters=360
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=240
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=360
size=3
stride=1
pad=1
activation=leaky

[convolutional]
filters=102
size=1
stride=1
pad=1
activation=linear

[yolo]
mask = 6,7,8
anchors = 12,12, 24,24, 20,20, 32,32, 48,48, 68,68, 100,100, 140,140, 140,220
classes=29
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
input_size= 16


[route]
layers = -4

[convolutional]
batch_normalize=1
filters=160
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 40

[convolutional]
batch_normalize=1
filters=160
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=240
activation=leaky

[convolutional]
batch_normalize=1
filters=160
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=240
activation=leaky

[convolutional]
batch_normalize=1
filters=160
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=240
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=102
activation=linear


[yolo]
mask = 3,4,5
anchors = 12,12, 24,24, 20,20, 32,32, 48,48, 68,68, 100,100, 140,140, 140,220
classes=29
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
input_size= 32


[route]
layers = -4

[convolutional]
batch_normalize=1
filters=96
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 24



[convolutional]
batch_normalize=1
filters=96
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=160
activation=leaky

[convolutional]
batch_normalize=1
filters=96
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=160
activation=leaky

[convolutional]
batch_normalize=1
filters=96
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=160
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=102
activation=linear


[yolo]
mask = 0,1,2
anchors = 12,12, 24,24, 20,20, 32,32, 48,48, 68,68, 100,100, 140,140, 140,220
classes=29
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
input_size= 64